{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import os\n",
    "%matplotlib inline\n",
    "import keras\n",
    "#from tensorflow.keras.preprocessing import ImageDataGenerator \n",
    "from keras.layers import Dense, Input, Dropout,Flatten, Conv2D\n",
    "from keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.utils import plot_model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from IPython.display import SVG, Image\n",
    "from livelossplot.tf_keras import PlotLossesCallback\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json_file = open('model5.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = tf.keras.models.model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_weights5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 2,835,074\n",
      "Trainable params: 2,831,874\n",
      "Non-trainable params: 3,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "import threading\n",
    "converter = pyttsx3.init() \n",
    "#voice_id=\"HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_EN-US_DAVID_11.0\"\n",
    "voice_id=\"HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_EN-US_ZIRA_11.0\"\n",
    "converter.setProperty('voice', voice_id) \n",
    "converter.setProperty('rate',150)\n",
    "#class threading.Thread(group=None, target=None, name=None, args=(), kwargs={}, *, daemon=None)\n",
    "\n",
    "class myThread (threading.Thread):\n",
    "    def voice(self):\n",
    "        converter.say(\"Put on your mask\")\n",
    "        converter.runAndWait() \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting Video Stream...\n",
      "[INFO] elasped time: 19.75\n",
      "[INFO] approx. FPS: 5.06\n"
     ]
    }
   ],
   "source": [
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import face_recognition\n",
    "import imutils\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "def start_camera():\n",
    "\n",
    "    print(\"[INFO] Starting Video Stream...\")\n",
    "    vs = VideoStream(src=0).start()\n",
    "    # vs = VideoStream(usePiCamera=True).start()\n",
    "    time.sleep(2.0)\n",
    "    detector = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    fps = FPS().start()\n",
    "    EMOTIONS_LIST=[\"With mask\",\"Without_mask\"]\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        frame = vs.read()\n",
    "        frame = imutils.resize(frame, width=1000)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        rects = detector.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        boxes = [(y, x + w, y + h, x) for (x, y, w, h) in rects]\n",
    "        accuracy = detect_faces(gray, rects)\n",
    "        \n",
    "        for ((top, right, bottom, left), accuracy) in zip(boxes,accuracy):\n",
    "            color=(0,255,0)\n",
    "            if accuracy==1:\n",
    "                #p1=myThread()\n",
    "                #p1.voice()\n",
    "                color=(0,0,255)\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "            y = top - 35 if top - 15 > 15 else top + 35\n",
    "            if accuracy==1:\n",
    "                cv2.putText(frame,\"Take precautions\",(40,500),font, 0.8,(0,0,255),2)\n",
    "            cv2.putText(frame, EMOTIONS_LIST[accuracy], (left, y), cv2.FONT_HERSHEY_SIMPLEX, 0.75, color, 2)\n",
    "\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "        fps.update()\n",
    "\n",
    "    fps.stop()\n",
    "    print(\"[INFO] elasped time: {:.2f}\".format(fps.elapsed()))\n",
    "    print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "    cv2.destroyAllWindows()\n",
    "    vs.stop()\n",
    "    \n",
    "    \n",
    "    \n",
    "def detect_faces(gray,rects):\n",
    "    sen2=[]\n",
    "    for (x,y,w,h) in rects:\n",
    "            gray2=gray[y:y+h,x:x+w]\n",
    "            gray3=cv2.resize(gray2,(48,48))\n",
    "            sen=loaded_model.predict(gray3[np.newaxis, :, :, np.newaxis])\n",
    "            pos=np.argmax(sen)\n",
    "            sen2.append(pos)\n",
    "    return sen2\n",
    "\n",
    "            \n",
    "start_camera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
